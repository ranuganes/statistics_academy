{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis - Statistics Academy 2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNW3K2DvcOHuT03g31HvVfs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranuganes/statistics_academy/blob/master/Sentiment_Analysis_Statistics_Academy_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvLLejapoxbt"
      },
      "source": [
        "# **Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3HDWI3vqhZP"
      },
      "source": [
        "Pada tutorial ini, kita akan menggunakan data product review dari salah satu ecommerce yang ada di Indonesia. Metode yang akan kita gunakan adalah **Support Vector Machine (SVM)**. Sentimen negatif mewakili review dengan bintang 1 dan 2, sedangkan sentimen positif mewakili review dengan bintang 4 dan 5.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BbA1JI256RH"
      },
      "source": [
        "Install library yang dibutuhkan (tidak tersedia pada google colab default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDlLAiVc52BZ"
      },
      "source": [
        "!pip install Sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqpQwZEzpJzi"
      },
      "source": [
        "## **1. Load Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hglOuglybzA"
      },
      "source": [
        "Create folder \"statistics_academy\" pada google drive. Pastikan folder tersebut berada di root (bagian terluar google drive). \n",
        "\n",
        "Open link ini\n",
        "[statistics_academy folder](https://drive.google.com/drive/u/0/folders/1sy8Y2Jz5qapQCJxG8n9a5ob7Ul3Okh6F), lalu copy file \"dataset_product_review.csv\" ke dalam folder \"statistics_academy\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLHukBP60FAs"
      },
      "source": [
        "Connect google colab dengan google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaJL1jDut-HT",
        "outputId": "56f16651-b2ae-4f49-a895-1af8c2b83573"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiDK7Jzy0a9g"
      },
      "source": [
        "Load dataset ke dalam dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isP4JfUktFva"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/statistics_academy/dataset_product_review.csv')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpXdOvUN1R6J"
      },
      "source": [
        "## **2. Preprocessing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8RYn0V72LA5"
      },
      "source": [
        "Preprocessing adalah proses pada data sebelum data dibuat dalam bentuk vektor, seperti:\n",
        "* Convert to lowercase\n",
        "* Replace double space with single space\n",
        "* Remove punctuation\n",
        "* Stemming (ubah kata berimbuhan menjadi kata dasar)\n",
        "* Singkatan atau abreviasi\n",
        "* Typo handling\n",
        "* Slang word / kata gaul\n",
        "* Handling imbalance data\n",
        "* dll (sesuai dengan kebutuhan dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVfOMJMZ6HDp"
      },
      "source": [
        "Berikut preprocessing data yang digunakan dan disiapkan dalam bentuk function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bzZ0XZlwtu2"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from string import punctuation\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# ? Initialization\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def convert_to_lower_case(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    for x in punctuation:\n",
        "        text = text.replace(x, \" \")\n",
        "    return text\n",
        "\n",
        "def remove_double_space(text):\n",
        "    text = re.sub('\\s+',' ',text)\n",
        "    return text.strip()\n",
        "\n",
        "def stemming(text):\n",
        "    text = stemmer.stem(text)\n",
        "    return text\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    text = convert_to_lower_case(text)\n",
        "    text = remove_punctuation(text)\n",
        "    text = remove_double_space(text)\n",
        "    # text = stemming(text)\n",
        "    return text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17AvStR81hm_"
      },
      "source": [
        "Lakukan preprocessing pada data review dan dimasukkan kedalam column \"cleaned_text\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QA-w124m5WJb"
      },
      "source": [
        "df['cleaned_text'] = [preprocessing_text(x) for x in df['text']]\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9knis5i8p3D"
      },
      "source": [
        "Masukkan \"cleaned_text\" dan \"label\" column masing-masing kedalam object list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F18lcUDS84wc"
      },
      "source": [
        "X = df['cleaned_text'].values.tolist()\n",
        "y = df['label'].values.tolist()"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTLeuQPB9cSM"
      },
      "source": [
        "Encode label / variable y menjadi numeric. Karena hanya dua kelas, maka bisa diubah menjadi 0 dan 1. Lalu buat label_map nya untuk mengembalikan nilai 0 dan 1 dalam text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgG2PxFZ6KYw"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "label = labelencoder.fit(y)\n",
        "\n",
        "label_map = {}\n",
        "for i,x in enumerate(list(label.classes_)):\n",
        "  label_map.update({i:x})\n",
        "print(label_map)\n",
        "\n",
        "y = label.transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2hUDLoICeNq"
      },
      "source": [
        "Split dataset menjadi data train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ14PDEGCdrE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=6)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjwrNm0E-BVb"
      },
      "source": [
        "## **3. Vectorizing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_hLjJuY_AV9"
      },
      "source": [
        "Vectorizing adalah proses mengubah data teks kedalam vector. \n",
        "\n",
        "Ada beberapa metode dalam mentransformasi teks kedalam vector:\n",
        "* Bag of Words Model\n",
        "* TF-IDF (Term Frequency and Inverse Document Frequency)\n",
        "* Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeJhFVU0AtGr"
      },
      "source": [
        "Pada tutorial ini, vectorizing akan menggunakan TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNDrbbGo7McT"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# ? Create feature vectors\n",
        "vectorizer = TfidfVectorizer(min_df = 5, max_df = 0.8)\n",
        "\n",
        "train_vectors = vectorizer.fit_transform(X_train)\n",
        "test_vectors = vectorizer.transform(X_test)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwVVZ_gOFNAp"
      },
      "source": [
        "## **4. Building Sentiment Analysis Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgCVwAG9Fh5R"
      },
      "source": [
        "Metode yang digunakan adalah Support Vector Machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvBMTZQk7Ndu",
        "outputId": "9f6e071c-d6f9-4155-ae53-d757f524846b"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "model = svm.SVC(C=1.0, gamma='auto' ,kernel='rbf', random_state=6)\n",
        "model.fit(train_vectors, y_train)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=6, shrinking=True, tol=0.001,\n",
              "    verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_VMXh6rHPep"
      },
      "source": [
        "Evaluasi model dengan data testing yang telah di split sebelumnya. Hal ini merepresentasikan data baru atau data yang belum pernah ditemui sebelumnya."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-OfDd--Fve1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(test_vectors)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5WDwkdSJSOF"
      },
      "source": [
        "## **5. Fine-tune Model / Model Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgyHklZVJZs9"
      },
      "source": [
        "Tahap ini adalah proses menemukan hasil yang maksimal dari model berdasarkan kombinasi **hyperparameter** yang ada. Salah satu hyperparameter dari SVM adalah kernel. \n",
        "\n",
        "Secara umum, fungsi kernel RBF direkomendasikan sebagai fungsi kernel pada SVM (Hsu, 2013). Dikarenakan menggunakan kernel RBF, maka hyperparameter yang dapat dioptimasi adalah **C** dan **Gamma**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XZspvbrK8ik"
      },
      "source": [
        "**Grid-search** adalah salah satu prosedur pemilihan model yang\n",
        "direkomendasikan untuk menentukan nilai optimal dari\n",
        "parameter C dan Gamma (Hsu, 2013)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMKP-TL7I7xE"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'kernel':['rbf'], 'C':[0.001, 0.01, 0.1, 1, 10], 'gamma':[0.001, 0.01, 0.1, 1, 10]}\n",
        "\n",
        "svc = svm.SVC(random_state=6)\n",
        "fine_tuned_model = GridSearchCV(estimator=svc, param_grid = param_grid, cv=5)\n",
        "fine_tuned_model.fit(train_vectors, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikSoIS1BNBZq"
      },
      "source": [
        "fine_tuned_model.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0skYJX_Nmhq"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = fine_tuned_model.predict(test_vectors)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6fWO-uIP26h"
      },
      "source": [
        "-------"
      ]
    }
  ]
}